{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Jupyter Notebook to train a model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 12:35:46.433961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# use random seed to reproduce results\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "lists possible devices (CPU, GPU), used to check if GPU is recognized/exists"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 12:35:49.508380: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-06 12:35:49.515645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-06 12:35:49.575862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 12:35:49.576076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.8225GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2021-12-06 12:35:49.576101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-06 12:35:49.606929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-06 12:35:49.607032: I tensorflow/stream_executor/pl"
     ]
    },
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "atform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-06 12:35:49.623277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-06 12:35:49.627922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-06 12:35:49.658841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-06 12:35:49.663387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-06 12:35:49.722320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-06 12:35:49.722470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 12:35:49.722818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 12:35:49.722951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "tf.config.get_visible_devices()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### used to save a trained model as a json file and its weights as a h5 file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    my_model = model.to_json()\n",
    "    with open(f'./saved_models/{model_name}.json', \"w\") as file:\n",
    "        file.write(my_model)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(f'./saved_models/{model_name}_weights.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### used to build the base model using predefined architectures\n",
    "currently: vgg16, xception, resnet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def build_base_model(architecture, weights):\n",
    "    input = tf.keras.Input(shape=(224, 224, 3))\n",
    "    if architecture == 'vgg16':\n",
    "        return tf.keras.applications.vgg16.VGG16(weights=weights,include_top=False,input_tensor=input)\n",
    "    if architecture == 'xception':\n",
    "        return tf.keras.applications.xception.Xception(weights=weights,include_top=False,input_tensor=input)\n",
    "    if architecture == 'resnet':\n",
    "        return tf.keras.applications.resnet.ResNet50(weights=weights,include_top=False,input_tensor=input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gets base model as input and builds a new top layer and returns the model with custom top layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def build_model(base_model):\n",
    "    flat = keras.layers.Flatten(name='flatten')(base_model.output)\n",
    "    dense_1 = keras.layers.Dense(1000)(flat)\n",
    "    dropout = keras.layers.Dropout(0.25)(dense_1)\n",
    "    batch = keras.layers.BatchNormalization()(dropout)\n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(batch)\n",
    "    return tf.keras.Model(base_model.input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gets a model as input and returns a model compiled with the adam optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def compile_model(model, alpha, beta1, beta2, metrics):\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=alpha, beta_1=beta1, beta_2=beta2)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=metrics)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gets a model as input and trains it on the data-set with the defined callbacks and epochs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def train_model(model, train_set, test_set, epochs, callback):\n",
    "    return model.fit(train_set,\n",
    "                     validation_data=test_set,\n",
    "                     epochs=epochs,\n",
    "                     callbacks=callback)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gets a model as input and changes its layers trainable attribute"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def set_layers_trainable(trainable, input_model):\n",
    "    for layer in input_model.layers:\n",
    "        layer.trainable = trainable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "preprocessing of the images applied when loading image data set from disk with tensorflows flow_from_directory\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "image_gen = keras.preprocessing.image.ImageDataGenerator(rotation_range=20,  # rotate the image 20 degrees\n",
    "                                                         width_shift_range=0.2,\n",
    "                                                         height_shift_range=0.2,\n",
    "                                                         rescale=1 / 255,  # Rescale the image by normalzing it.\n",
    "                                                         shear_range=0.15,\n",
    "                                                         # Shear means cutting away part of the image (max 20%)\n",
    "                                                         zoom_range=0.15,  # Zoom in by 15% max\n",
    "                                                         horizontal_flip=True,  # Allow horizontal flipping\n",
    "                                                         fill_mode='nearest'\n",
    "                                                         # Fill in missing pixels with the nearest filled value\n",
    "                                                         )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "path to the data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "train_data_path = './data/data_heavily_reduced/data_balanced/train'  #local notebook\n",
    "test_data_path = './data/data_heavily_reduced/data_balanced/test'  #local notebook\n",
    "validation_data_path = './data/data_heavily_reduced/data_balanced/val'  #local notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "generate training set by loading the images from their directories with flow_from_directory\n",
    "important: the folder structure has to match! i.e {train} -> {ok,def}\n",
    "at the \"same time\" the data augmentation is applied on the images through the ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7999 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image_gen = image_gen.flow_from_directory(train_data_path,\n",
    "                                                target_size=(224, 224),\n",
    "                                                class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 999 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_image_gen = image_gen.flow_from_directory(validation_data_path,\n",
    "                                                target_size=(224, 224),\n",
    "                                                class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image_gen = image_gen.flow_from_directory(test_data_path,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training of the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* build base model with vgg16 architecture and pretrained with imagenet weights\n",
    "* add custom layers on base model\n",
    "* compile model with adam optimizer\n",
    "* freeze layers of pretrained vgg16 base model to not destroy imagenet weights\n",
    "* train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "164/250 [==================>...........] - ETA: 31s - loss: 0.4113 - accuracy: 0.8356 - recall: 0.8435 - precision: 0.8321 - auc: 0.9068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 13:08:19.587442: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-06 13:08:19.587496: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-06 13:08:19.733622: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.74GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-06 13:08:20.357028: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.68GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-06 13:08:20.357078: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-06 13:08:21.305912: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-06 13:08:22.200230: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-06 13:08:23.604244: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-12-06 13:08:23.915512: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 113s 449ms/step - loss: 0.3675 - accuracy: 0.8546 - recall: 0.8638 - precision: 0.8497 - auc: 0.9241 - val_loss: 1.7376 - val_accuracy: 0.6144 - val_recall: 1.0000 - val_precision: 0.5648 - val_auc: 0.8662\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 110s 438ms/step - loss: 0.1437 - accuracy: 0.9445 - recall: 0.9533 - precision: 0.9373 - auc: 0.9869 - val_loss: 0.1298 - val_accuracy: 0.9441 - val_recall: 0.8902 - val_precision: 0.9978 - val_auc: 0.9946\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 106s 421ms/step - loss: 0.0963 - accuracy: 0.9638 - recall: 0.9693 - precision: 0.9583 - auc: 0.9940 - val_loss: 0.2716 - val_accuracy: 0.8891 - val_recall: 0.7784 - val_precision: 1.0000 - val_auc: 0.9947\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.0886 - accuracy: 0.9620 - recall: 0.9708 - precision: 0.9544 - auc: 0.9951 - val_loss: 0.0578 - val_accuracy: 0.9780 - val_recall: 0.9601 - val_precision: 0.9959 - val_auc: 0.9981\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 100s 397ms/step - loss: 0.0679 - accuracy: 0.9757 - recall: 0.9784 - precision: 0.9730 - auc: 0.9969 - val_loss: 0.1753 - val_accuracy: 0.9201 - val_recall: 1.0000 - val_precision: 0.8623 - val_auc: 0.9980\n"
     ]
    }
   ],
   "source": [
    "vgg16 = build_base_model('vgg16', 'imagenet')\n",
    "model = build_model(vgg16)\n",
    "model = compile_model(model, 0.0001, 0.9, 0.999, ['accuracy', 'Recall', 'Precision', 'AUC'])\n",
    "set_layers_trainable(False, vgg16)\n",
    "history = train_model(model, train_image_gen, test_image_gen, 5, [])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* un freeze layers of pretrained vgg16 base model\n",
    "* define callbacks\n",
    "    * tensorboard callback to generate reports which can be viewed in tensorboard\n",
    "    * early stopping callback to stop training after monitored metric has not changed after, by the patience defined, epochs\n",
    "* compile model with adam optimizer\n",
    "* train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 13:20:29.322337: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-06 13:20:29.322361: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-06 13:20:29.322631: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2021-12-06 13:20:29.331522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2021-12-06 13:20:29.432615: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2021-12-06 13:20:29.432775: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/250 [..............................] - ETA: 5:23 - loss: 0.0875 - accuracy: 0.9688 - recall: 0.9500 - precision: 1.0000 - auc: 0.9958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 13:20:31.076867: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-06 13:20:31.076888: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-06 13:20:31.077294: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/250 [..............................] - ETA: 1:09 - loss: 0.0695 - accuracy: 0.9766 - recall: 0.9607 - precision: 1.0000 - auc: 0.9969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 13:20:31.333021: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-12-06 13:20:31.337220: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-12-06 13:20:31.338865: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-06 13:20:31.342841: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_12_06_13_20_31\n",
      "2021-12-06 13:20:31.343501: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/train/plugins/profile/2021_12_06_13_20_31/pop-os.trace.json.gz\n",
      "2021-12-06 13:20:31.353036: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_12_06_13_20_31\n",
      "2021-12-06 13:20:31.355347: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/train/plugins/profile/2021_12_06_13_20_31/pop-os.memory_profile.json.gz\n",
      "2021-12-06 13:20:31.355553: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/train/plugins/profile/2021_12_06_13_20_31Dumped tool data for xplane.pb to ./logs/train/plugins/profile/2021_12_06_13_20_31/pop-os.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/train/plugins/profile/2021_12_06_13_20_31/pop-os.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/train/plugins/profile/2021_12_06_13_20_31/pop-os.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/train/plugins/profile/2021_12_06_13_20_31/pop-os.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/train/plugins/profile/2021_12_06_13_20_31/pop-os.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/250 [======================>.......] - ETA: 13s - loss: 0.0590 - accuracy: 0.9796 - recall: 0.9823 - precision: 0.9778 - auc: 0.9970"
     ]
    }
   ],
   "source": [
    "set_layers_trainable(False, vgg16)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "custom_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "model = compile_model(model, 0.0001, 0.9, 0.999, ['accuracy', 'Recall', 'Precision', 'AUC'])\n",
    "history = train_model(model, train_image_gen, test_image_gen, 100, [custom_early_stopping, tensorboard_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation of the model on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, accuracy, recall, precision, auc = model.evaluate(test_image_gen)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# F1 score\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "print(f\"loss: {loss}, \\n\"\n",
    "      f\"accuracy: {accuracy}, \\n\"\n",
    "      f\"recall: {recall}, \\n\"\n",
    "      f\"precision: {precision}, \\n\"\n",
    "      f\"auc: {auc}, \\n\"\n",
    "      f\"F1: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving the model to use it for predictions, heatmaps, etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_6611/2052068010.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0msave_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'vgg16'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_6611/1993119991.py\u001B[0m in \u001B[0;36msave_model\u001B[0;34m(model, model_name)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0msave_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mmy_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'./saved_models/{model_name}.json'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"w\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfile\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0mfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmy_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;31m# serialize weights to HDF5\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'History' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": [
    "save_model(model, 'vgg16')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8f8e9c42",
   "language": "python",
   "display_name": "PyCharm (Quality Control of SLS manufacturing using Convolutional Neural Networks -implementation)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}