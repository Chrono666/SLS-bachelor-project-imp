{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Jupyter Notebook to train a model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:04:34.001788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tf_explain.callbacks.grad_cam import GradCAMCallback\n",
    "\n",
    "# use random seed to reproduce results\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "lists possible devices (CPU, GPU), used to check if GPU is recognized/exists"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:04:38.272739: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:04:38.273599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-06 19:04:38.330805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 19:04:38.330990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.8225GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2021-12-06 19:04:38.331011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-06 19:04:38.332986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-06 19:04:38.333125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-06 19:04:38.335337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-06 19:04:38.335750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-06 19:04:38.337563: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-06 19:04:38.339122: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-06 19:04:38.342602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-06 19:04:38.342782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 19:04:38.342983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 19:04:38.343072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "tf.config.get_visible_devices()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### used to save a trained model as a json file and its weights as a h5 file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    my_model = model.to_json()\n",
    "    with open(f'./saved_models/{model_name}.json', \"w\") as file:\n",
    "        file.write(my_model)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(f'./saved_models/{model_name}_weights.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### used to build the base model using predefined architectures\n",
    "currently: vgg16, xception, resnet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def build_base_model(architecture, weights):\n",
    "    input = tf.keras.Input(shape=(224, 224, 3))\n",
    "    if architecture == 'vgg16':\n",
    "        return tf.keras.applications.vgg16.VGG16(weights=weights, include_top=False, input_tensor=input)\n",
    "    if architecture == 'xception':\n",
    "        return tf.keras.applications.xception.Xception(weights=weights, include_top=False, input_tensor=input)\n",
    "    if architecture == 'resnet':\n",
    "        return tf.keras.applications.resnet.ResNet50(weights=weights, include_top=False, input_tensor=input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gets base model as input and builds a new top layer and returns the model with custom top layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def build_model(base_model):\n",
    "    flat = keras.layers.Flatten(name='flatten')(base_model.output)\n",
    "    dense_1 = keras.layers.Dense(1000)(flat)\n",
    "    dropout = keras.layers.Dropout(0.25)(dense_1)\n",
    "    batch = keras.layers.BatchNormalization()(dropout)\n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(batch)\n",
    "    return tf.keras.Model(base_model.input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gets a model as input and returns a model compiled with the adam optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compile_model(model, alpha, beta1, beta2, metrics):\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=alpha, beta_1=beta1, beta_2=beta2)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=metrics)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gets a model as input and trains it on the data-set with the defined callbacks and epochs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_model(model, train_set, validation_set, epochs, callback):\n",
    "    return model.fit(train_set,\n",
    "                     validation_data=validation_set,\n",
    "                     epochs=epochs,\n",
    "                     callbacks=callback)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### gets a model as input and changes its layers trainable attribute"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def set_layers_trainable(trainable, input_model):\n",
    "    for layer in input_model.layers:\n",
    "        layer.trainable = trainable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "preprocessing of the images applied when loading image data set from disk with tensorflows flow_from_directory\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "image_gen = keras.preprocessing.image.ImageDataGenerator(rotation_range=20,  # rotate the image 20 degrees\n",
    "                                                         width_shift_range=0.2,\n",
    "                                                         height_shift_range=0.2,\n",
    "                                                         rescale=1 / 255,  # Rescale the image by normalzing it.\n",
    "                                                         shear_range=0.15,\n",
    "                                                         # Shear means cutting away part of the image (max 20%)\n",
    "                                                         zoom_range=0.15,  # Zoom in by 15% max\n",
    "                                                         horizontal_flip=True,  # Allow horizontal flipping\n",
    "                                                         fill_mode='nearest'\n",
    "                                                         # Fill in missing pixels with the nearest filled value\n",
    "                                                         )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "path to the data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_data_path = './data/data_heavily_reduced/data_balanced/train'  #local notebook\n",
    "test_data_path = './data/data_heavily_reduced/data_balanced/test'  #local notebook\n",
    "validation_data_path = './data/data_heavily_reduced/data_balanced/val'  #local notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "generate training set by loading the images from their directories with flow_from_directory\n",
    "important: the folder structure has to match! i.e {train} -> {ok,def}\n",
    "at the \"same time\" the data augmentation is applied on the images through the ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7999 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image_gen = image_gen.flow_from_directory(train_data_path,\n",
    "                                                target_size=(224, 224),\n",
    "                                                class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 999 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_image_gen = image_gen.flow_from_directory(validation_data_path,\n",
    "                                                target_size=(224, 224),\n",
    "                                                class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image_gen = image_gen.flow_from_directory(test_data_path,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training of the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre Training\n",
    "* build base model with vgg16 architecture and pretrained with imagenet weights\n",
    "* add custom layers on base model\n",
    "* compile model with adam optimizer\n",
    "* freeze layers of pretrained vgg16 base model to not destroy imagenet weights\n",
    "* train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:04:56.462578: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-06 19:04:56.462984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 19:04:56.463114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.8225GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2021-12-06 19:04:56.463145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-06 19:04:56.463186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-06 19:04:56.463201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-06 19:04:56.463213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-06 19:04:56.463224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-06 19:04:56.463235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-06 19:04:56.463246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-06 19:04:56.463257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-06 19:04:56.463312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 19:04:56.463430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 19:04:56.463511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-06 19:04:56.463536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-06 19:04:56.881358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-06 19:04:56.881385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-12-06 19:04:56.881390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-12-06 19:04:56.881557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 19:04:56.881719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 19:04:56.881838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 19:04:56.881936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5939 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2021-12-06 19:04:56.882157: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-06 19:04:57.632942: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-06 19:04:57.650589: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3999980000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:04:59.071855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-06 19:04:59.368990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-06 19:04:59.863236: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-12-06 19:04:59.896238: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-12-06 19:05:11.953312: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/250 [==================>...........] - ETA: 30s - loss: 0.4225 - accuracy: 0.8313 - recall: 0.8376 - precision: 0.8333 - auc: 0.9039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:06:24.883311: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 146s 524ms/step - loss: 0.3642 - accuracy: 0.8554 - recall: 0.8617 - precision: 0.8548 - auc: 0.9251 - val_loss: 0.1144 - val_accuracy: 0.9590 - val_recall: 1.0000 - val_precision: 0.9244 - val_auc: 0.9968\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 115s 459ms/step - loss: 0.1277 - accuracy: 0.9497 - recall: 0.9538 - precision: 0.9443 - auc: 0.9895 - val_loss: 0.0482 - val_accuracy: 0.9850 - val_recall: 0.9860 - val_precision: 0.9841 - val_auc: 0.9987\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 141s 560ms/step - loss: 0.0888 - accuracy: 0.9674 - recall: 0.9701 - precision: 0.9662 - auc: 0.9945 - val_loss: 0.1351 - val_accuracy: 0.9441 - val_recall: 1.0000 - val_precision: 0.8995 - val_auc: 0.9987\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 124s 497ms/step - loss: 0.0961 - accuracy: 0.9646 - recall: 0.9658 - precision: 0.9637 - auc: 0.9937 - val_loss: 0.1606 - val_accuracy: 0.9341 - val_recall: 0.9960 - val_precision: 0.8863 - val_auc: 0.9965\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 110s 440ms/step - loss: 0.0759 - accuracy: 0.9715 - recall: 0.9747 - precision: 0.9678 - auc: 0.9961 - val_loss: 0.0421 - val_accuracy: 0.9900 - val_recall: 0.9920 - val_precision: 0.9881 - val_auc: 0.9994\n"
     ]
    }
   ],
   "source": [
    "vgg16 = build_base_model('vgg16', 'imagenet')\n",
    "model = build_model(vgg16)\n",
    "model = compile_model(model, 0.0001, 0.9, 0.999, ['accuracy', 'Recall', 'Precision', 'AUC'])\n",
    "set_layers_trainable(False, vgg16)\n",
    "history = train_model(model, train_image_gen, test_image_gen, 5, [])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Full Training\n",
    "* un freeze layers of pretrained vgg16 base model\n",
    "* define callbacks\n",
    "    * tensorboard callback to generate reports which can be viewed in tensorboard\n",
    "    * early stopping callback to stop training after monitored metric has not changed after, by the patience defined, epochs\n",
    "* compile model with adam optimizer\n",
    "* train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "set_layers_trainable(True, vgg16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 18:45:53.414652: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-06 18:45:53.414674: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-06 18:45:53.414694: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2021-12-06 18:45:53.415241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2021-12-06 18:45:53.515541: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2021-12-06 18:45:53.515837: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=5, write_graph=True, write_images=True)\n",
    "custom_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/250 [..............................] - ETA: 7:30 - loss: 0.0457 - accuracy: 0.9688 - recall: 1.0000 - precision: 0.9231 - auc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 18:52:25.843420: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-06 18:52:25.843451: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-06 18:52:25.844023: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/250 [..............................] - ETA: 1:49 - loss: 0.0867 - accuracy: 0.9688 - recall: 0.9839 - precision: 0.9454 - auc: 0.9905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 18:52:26.236676: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-12-06 18:52:26.240232: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-12-06 18:52:26.241644: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-06 18:52:26.243437: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_12_06_18_52_26\n",
      "2021-12-06 18:52:26.244167: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/train/plugins/profile/2021_12_06_18_52_26/pop-os.trace.json.gz\n",
      "2021-12-06 18:52:26.259187: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_12_06_18_52_26\n",
      "2021-12-06 18:52:26.262823: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/train/plugins/profile/2021_12_06_18_52_26/pop-os.memory_profile.json.gz\n",
      "2021-12-06 18:52:26.263150: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/train/plugins/profile/2021_12_06_18_52_26Dumped tool data for xplane.pb to ./logs/train/plugins/profile/2021_12_06_18_52_26/pop-os.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/train/plugins/profile/2021_12_06_18_52_26/pop-os.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/train/plugins/profile/2021_12_06_18_52_26/pop-os.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/train/plugins/profile/2021_12_06_18_52_26/pop-os.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/train/plugins/profile/2021_12_06_18_52_26/pop-os.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 98s 385ms/step - loss: 0.0855 - accuracy: 0.9699 - recall: 0.9728 - precision: 0.9675 - auc: 0.9941 - val_loss: 0.3981 - val_accuracy: 0.8781 - val_recall: 1.0000 - val_precision: 0.8042 - val_auc: 0.9796\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_43688/3697734707.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompile_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.0001\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.9\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.999\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'accuracy'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Recall'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Precision'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'AUC'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m history = train_model(model, train_image_gen, test_image_gen, 100,\n\u001B[0m\u001B[1;32m      3\u001B[0m                       [custom_early_stopping, tensorboard_callback, grad_cam_callback])\n",
      "\u001B[0;32m/tmp/ipykernel_43688/663974549.py\u001B[0m in \u001B[0;36mtrain_model\u001B[0;34m(model, train_set, validation_set, epochs, callback)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidation_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     return model.fit(train_set,\n\u001B[0m\u001B[1;32m      3\u001B[0m                      \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidation_set\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m                      \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                      callbacks=callback)\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1143\u001B[0m           \u001B[0mepoch_logs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_logs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1145\u001B[0;31m         \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_epoch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch_logs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1146\u001B[0m         \u001B[0mtraining_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mepoch_logs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1147\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstop_training\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001B[0m in \u001B[0;36mon_epoch_end\u001B[0;34m(self, epoch, logs)\u001B[0m\n\u001B[1;32m    430\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mnumpy_logs\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# Only convert once.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    431\u001B[0m           \u001B[0mnumpy_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_numpy_or_python_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 432\u001B[0;31m         \u001B[0mcallback\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_epoch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumpy_logs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    433\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tf_explain/callbacks/grad_cam.py\u001B[0m in \u001B[0;36mon_epoch_end\u001B[0;34m(self, epoch, logs)\u001B[0m\n\u001B[1;32m     58\u001B[0m         \"\"\"\n\u001B[1;32m     59\u001B[0m         \u001B[0mexplainer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGradCAM\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m         heatmap = explainer.explain(\n\u001B[0m\u001B[1;32m     61\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidation_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tf_explain/core/grad_cam.py\u001B[0m in \u001B[0;36mexplain\u001B[0;34m(self, validation_data, model, class_index, layer_name, use_guided_grads, colormap, image_weight)\u001B[0m\n\u001B[1;32m     52\u001B[0m             \u001B[0mlayer_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfer_grad_cam_target_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         outputs, grads = GradCAM.get_gradients_and_filters(\n\u001B[0m\u001B[1;32m     55\u001B[0m             \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayer_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muse_guided_grads\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         )\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tf_explain/core/grad_cam.py\u001B[0m in \u001B[0;36mget_gradients_and_filters\u001B[0;34m(model, images, layer_name, class_index, use_guided_grads)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    114\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGradientTape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 115\u001B[0;31m             \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    116\u001B[0m             \u001B[0mtape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m             \u001B[0mconv_outputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrad_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 201\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36mcast\u001B[0;34m(x, dtype, name)\u001B[0m\n\u001B[1;32m    962\u001B[0m       \u001B[0;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    963\u001B[0m       \u001B[0;31m# strings.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 964\u001B[0;31m       \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"x\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    965\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_dtype\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mbase_type\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    966\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbase_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    161\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrace_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mtrace_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m           \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 163\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    164\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1538\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1539\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1540\u001B[0;31m       \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconversion_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mas_ref\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1541\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1542\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mNotImplemented\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001B[0m in \u001B[0;36m_default_conversion_function\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_default_conversion_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m   \u001B[0;32mdel\u001B[0m \u001B[0mas_ref\u001B[0m  \u001B[0;31m# Unused.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mconstant_op\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    262\u001B[0m     \u001B[0mValueError\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mcalled\u001B[0m \u001B[0mon\u001B[0m \u001B[0ma\u001B[0m \u001B[0msymbolic\u001B[0m \u001B[0mtensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    263\u001B[0m   \"\"\"\n\u001B[0;32m--> 264\u001B[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001B[0m\u001B[1;32m    265\u001B[0m                         allow_broadcast=True)\n\u001B[1;32m    266\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_impl\u001B[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    274\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"tf.constant\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    275\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 276\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    277\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m   \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_default_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_eager_impl\u001B[0;34m(ctx, value, dtype, shape, verify_shape)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m   \u001B[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 301\u001B[0;31m   \u001B[0mt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_to_eager_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    302\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mshape\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    303\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/sls/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m     96\u001B[0m       \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_datatype_enum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m   \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 98\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEagerTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     99\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor)."
     ]
    }
   ],
   "source": [
    "model = compile_model(model, 0.0001, 0.9, 0.999, ['accuracy', 'Recall', 'Precision', 'AUC'])\n",
    "history = train_model(model, train_image_gen, test_image_gen, 100,\n",
    "                      [custom_early_stopping, tensorboard_callback, grad_cam_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation of the model on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 8s 241ms/step - loss: 0.0188 - accuracy: 0.9950 - recall: 0.9960 - precision: 0.9940 - auc: 0.9998\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, recall, precision, auc = model.evaluate(test_image_gen)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.018838077783584595, \n",
      "accuracy: 0.9950050115585327, \n",
      "recall: 0.9960079789161682, \n",
      "precision: 0.9940239191055298, \n",
      "auc: 0.9997684955596924, \n",
      "F1: 0.9950149599580262\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "print(f\"loss: {loss}, \\n\"\n",
    "      f\"accuracy: {accuracy}, \\n\"\n",
    "      f\"recall: {recall}, \\n\"\n",
    "      f\"precision: {precision}, \\n\"\n",
    "      f\"auc: {auc}, \\n\"\n",
    "      f\"F1: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving the model to use it for predictions, heatmaps, etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "save_model(model, 'vgg16_heavily_reduced')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8f8e9c42",
   "language": "python",
   "display_name": "PyCharm (Quality Control of SLS manufacturing using Convolutional Neural Networks -implementation)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}